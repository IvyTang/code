# model configuration
init_scale 0.05
learning_rate 0.2
max_grad_norm 5
num_layers 2
num_steps 30
word_embedding_size 80
letter_embedding_size 80
hidden_size 400
max_epoch 2
keep_prob 0.75
lr_decay 0.8
batch_size 32
vocab_size_letter 33
vocab_size_in 7000
vocab_size_out 7000
max_max_epoch 10
buckets 5,10,20,30
gpu_fraction 0.98
